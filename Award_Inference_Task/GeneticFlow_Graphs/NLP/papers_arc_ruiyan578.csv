2021.naacl-main.134,Learning to Organize a Bag of Words into Sentences with Neural Networks: An Empirical Study,2021,-1,-1,6,1.0,3645,chongyang tao,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,0,0.0,0.0
2021.findings-acl.419,{B}io{G}en: Generating Biography Summary under Table Guidance on {W}ikipedia,2021,-1,-1,5,1.0,3646,shen gao,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,0,0.0,0.0
2021.findings-acl.432,Enhancing the Open-Domain Dialogue Evaluation in Latent Space,2021,-1,-1,7,1.0,8500,zhangming chan,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,0,0.0,0.0
2021.acl-long.343,A Pre-training Strategy for Zero-Resource Response Selection in Knowledge-Grounded Conversations,2021,-1,-1,5,1.0,3645,chongyang tao,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,0,0.0,0.0
2021.acl-long.473,Capturing Relations between Scientific Papers: An Abstractive Model for Related Work Section Generation,2021,-1,-1,7,1.0,6704,xiuying chen,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,0,0.0,0.0
2020.emnlp-main.272,Knowledge-Grounded Dialogue Generation with Pre-trained Language Models,2020,-1,-1,6,0.0,20313,xueliang zhao,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,0,0.0,0.0
2020.emnlp-main.281,Amalgamating Knowledge from Two Teachers for Task-oriented Dialogue System with Adversarial Training,2020,-1,-1,3,0.0,11211,wanwei he,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,0,0.0,0.0
2020.emnlp-main.313,Selection and Generation: Learning towards Multi-Product Advertisement Post Generation,2020,-1,-1,7,1.0,8500,zhangming chan,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,0,0.0,0.0
2020.emnlp-main.752,{VMSMO}: Learning to Generate Multimodal Summary for Video-based News Articles,2020,-1,-1,6,0.0,13377,mingzhe li,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,0,0.0,0.0
2020.coling-main.363,Translation vs. Dialogue: A Comparative Analysis of Sequence-to-Sequence Modeling,2020,-1,-1,6,0.0,19517,wenpeng hu,Proceedings of the 28th International Conference on Computational Linguistics,0,0,0.0,0.0
2020.ccl-1.83,Plan-{CVAE}: A Planning-based Conditional Variational Autoencoder for Story Generation,2020,-1,-1,3,0.0,22128,lin wang,Proceedings of the 19th Chinese National Conference on Computational Linguistics,0,0,0.0,0.0
2020.acl-main.517,Learning to Customize Model Structures for Few-shot Dialogue Generation Tasks,2020,29,0,4,1.0,22577,yiping song,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,0,0.5244419609498762,-0.6142436261693646
P19-1001,One Time of Interaction May Not Be Enough: Go Deep with an Interaction-over-Interaction Network for Response Selection in Dialogues,2019,0,10,6,1.0,3645,chongyang tao,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,0,-0.031362483355824,-0.032453646393453
P19-1370,Learning a Matching Model with Co-teaching for Multi-turn Response Selection in Retrieval-based Dialogue Systems,2019,0,4,6,0.0,13218,jiazhan feng,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,0,-0.031362483355824,-0.032453646393453
P19-1372,Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References,2019,0,4,5,0.0,25759,lisong qiu,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,0,-0.031362483355824,-0.032453646393453
D19-1128,Sampling Matters! An Empirical Study of Negative Sampling Strategies for Learning of Matching Models in Retrieval-based Dialogue Systems,2019,0,0,6,0.0,26839,jia li,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,0,-0.031362483355824,-0.032453646393453
D19-1199,Who Is Speaking to Whom? Learning to Identify Utterance Addressee in Multi-Party Conversations,2019,0,0,7,0.0,21460,ran le,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,0,-0.16447085566453823,-0.40294193477568313
D19-1201,Modeling Personalization in Continuous Space for Response Generation via Augmented {W}asserstein Autoencoders,2019,0,5,7,1.0,8500,zhangming chan,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,0,-0.23215179942539424,-0.1088834567445186
D19-1388,How to Write Summaries with Patterns? Learning towards Abstractive Summarization through Prototype Editing,2019,0,2,6,1.0,3646,shen gao,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,0,-0.1787956355762268,-0.39666807626292166
D19-1499,Semi-supervised Text Style Transfer: Cross Projection in Latent Space,2019,0,0,7,0.0,4675,mingyue shang,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,0,-0.031362483355824,-0.032453646393453
D19-1501,Stick to the Facts: Learning towards a Fidelity-oriented {E}-Commerce Product Description Generation,2019,0,1,8,1.0,8500,zhangming chan,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,0,-0.031362483355824,-0.032453646393453
P18-2070,Modeling discourse cohesion for discourse parsing via memory network,2018,0,7,5,0.0,29054,yanyan jia,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,0,0.23185760743802142,-0.3886521694675594
P18-1194,Marrying Up Regular Expressions with Neural Networks: A Case Study for Spoken Language Understanding,2018,0,5,5,0.0,19503,bingfeng luo,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,0,0.15745040299960442,0.06301632820772265
D18-3006,Deep Chit-Chat: Deep Learning for {C}hat{B}ots,2018,-1,-1,2,0.483682,3772,wei wu,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts,0,0,0.0,0.0
D18-1089,On the Abstractiveness of Neural Document Summarization,2018,0,5,3,0.0,30472,fangfang zhang,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,0,-0.19911879435043214,-1.0526538618911896
D18-1423,Generating Classical {C}hinese Poems via Conditional Variational Autoencoder and Adversarial Training,2018,0,9,7,1.0,3647,juntao li,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,0,-0.031362483355824,-0.032453646393453
D18-1442,Iterative Document Representation Learning Towards Summarization with Polishing,2018,0,4,6,1.0,6704,xiuying chen,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,0,-0.048025373834676775,-0.4182641797890792
P17-2036,How to Make Context More Useful? An Empirical Study on Context-Aware Neural Conversational Models,2017,10,32,2,0.0,12693,zhiliang tian,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,0,-0.031362483355824,-0.032453646393453
P17-1040,Learning with Noise: Enhance Distantly Supervised Relation Extraction with Dynamic Transition Matrix,2017,17,29,6,0.0,19503,bingfeng luo,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,0,-2.4747839883894183,-1.008987148886737
I17-2029,Diversifying Neural Conversation Model with Maximal Marginal Relevance,2017,11,4,5,1.0,22577,yiping song,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,0,-0.031362483355824,-0.032453646393453
D17-1233,Towards Implicit Content-Introducing for Generative Short-Text Conversation Systems,2017,20,21,5,0.0,22276,lili yao,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,0,0.2465397387970261,-0.3233486362814088
P16-2022,Natural Language Inference by Tree-Based Convolution and Heuristic Matching,2016,16,117,6,0.0,1040,lili mou,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,0,0.9516455680856496,0.4734218239228285
P16-1222,{C}hinese Couplet Generation with Neural Network Structures,2016,25,9,1,1.0,3650,rui yan,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,0,0.05067678173450452,-0.5982428919994542
O16-2003,Enriching Cold Start Personalized Language Model Using Social Network Information,2016,21,0,2,0.0,34564,yuyang huang,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 21, Number 1, June 2016",0,0,-0.0806403799125463,-0.1165534499722581
D16-1036,Multi-view Response Selection for Human-Computer Conversation,2016,16,84,8,0.0,25756,xiangyang zhou,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,0,-0.031362483355824,-0.032453646393453
D16-1046,How Transferable are Neural Networks in {NLP} Applications?,2016,23,56,3,0.0,1040,lili mou,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,0,-0.031362483355824,-0.032453646393453
C16-1316,Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation,2016,26,69,3,0.0,1040,lili mou,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,0,0.35683174342854224,-0.29763261207193487
P15-2103,"Tackling Sparsity, the Achilles Heel of Social Networks: Language Model Smoothing via Social Regularization",2015,24,2,1,1.0,3650,rui yan,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,0,-0.0806403799125463,-0.1165534499722581
P14-2100,Enriching Cold Start Personalized Language Model Using Social Network Information,2014,21,8,2,0.0,34564,yuyang huang,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,0,-0.0806403799125463,-0.1165534499722581
P14-1107,Are Two Heads Better than One? Crowdsourced Translation via a Two-Step Collaboration of Non-Professional Translators and Editors,2014,46,9,1,1.0,3650,rui yan,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,0,0.18602794150012567,-0.25320349094068173
I13-1058,Semantic v.s. Positions: Utilizing Balanced Proximity in Language Model Smoothing for Information Retrieval,2013,26,4,1,1.0,3650,rui yan,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,0,0.0736721251108524,-0.34636979298455334
P12-1054,Tweet Recommendation with Graph Co-Ranking,2012,29,67,1,1.0,3650,rui yan,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,0,0.0,0.0
D11-1040,Timeline Generation through Evolutionary Trans-Temporal Summarization,2011,20,50,1,1.0,3650,rui yan,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,0,0.07634622642037593,-0.38370130671341546
D11-1124,Summarize What You Are Interested In: An Optimization Framework for Interactive Personalized Summarization,2011,22,22,1,1.0,3650,rui yan,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,0,-0.3262287877966296,-0.7608825061323903
